{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9196d735-8b41-45ba-bbfb-f2b2d08fc87d",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2024-09-27T06:48:30.458305Z",
     "iopub.status.busy": "2024-09-27T06:48:30.457874Z",
     "iopub.status.idle": "2024-09-27T06:48:30.472198Z",
     "shell.execute_reply": "2024-09-27T06:48:30.471216Z",
     "shell.execute_reply.started": "2024-09-27T06:48:30.458283Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "closing parenthesis ')' does not match opening parenthesis '[' (1246743808.py, line 174)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[9], line 174\u001b[0;36m\u001b[0m\n\u001b[0;31m    examples.append(InputExample(texts=[qa_pair['query'], qa_pair['answer']))\u001b[0m\n\u001b[0m                                                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m closing parenthesis ')' does not match opening parenthesis '['\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain_community.document_loaders import PyMuPDFLoader, PyPDFLoader\n",
    "from sentence_transformers import InputExample, SentenceTransformer\n",
    "from sentence_transformers.evaluation import BinaryClassificationEvaluator\n",
    "from zhipuai import ZhipuAI\n",
    "from sentence_transformers import losses\n",
    "import re\n",
    "import json\n",
    "from langchain_core.documents import Document\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "class QaPairs():\n",
    "    '''存储List[dict]类型数据'''\n",
    "\n",
    "    def __init__(self, qa_pairs: List[dict]):\n",
    "        self.qa_pairs = qa_pairs\n",
    "        \n",
    " \n",
    "    def save_json(self, path: str):\n",
    "        '''将数据存储为json格式'''\n",
    "\n",
    "        with open(path, \"w\", encoding='utf-8') as f:\n",
    "            json.dump(self.qa_pairs, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    @classmethod\n",
    "    def from_json(cls, path:str) -> 'QaPairs':\n",
    "        '''读取json格式数据'''\n",
    "\n",
    "        with open(path) as f:\n",
    "            data = json.load(f)\n",
    "        return cls(data)\n",
    "\n",
    "\n",
    "llm_list = ['glm-4-flash', 'glm-4', 'glm-4v', 'glm-3-turbo', 'gpt-3.5-turbo']\n",
    "\n",
    "PROMPT = '''\n",
    "下面是上下文信息。\n",
    " \n",
    "--------------------- \n",
    "{context_str} \n",
    "--------------------- \n",
    " \n",
    "给定上下文信息，没有先验知识。 \n",
    "仅根据下面的查询生成问题。 \n",
    " \n",
    "你是一位老师/教授。你的任务是为即将到来的测验/考试设置{num_questions_per_page}个问题以及问题涉及到的原文内容\n",
    "在整个文件中，问题的性质应该是多样化的。\n",
    "将问题限制在提供的上下文信息之内。\n",
    "按照一下格式输出：\n",
    "问题1：\n",
    "问题\n",
    "\n",
    "原文内容1：\n",
    "原文内容\n",
    "\n",
    "的形式回答\n",
    "'''\n",
    "\n",
    "def list_generate_qa_pairs(\n",
    "        texts: List[str],\n",
    "        num_questions_per_page: int = 2,\n",
    "        model: str = 'glm-4',\n",
    ") -> QaPairs:\n",
    "    '''借助大模型从给定的texts里提取出问题与对应的答案'''\n",
    "\n",
    "    if model not in llm_list:\n",
    "        raise ValueError('你选择的模型暂时不被支持'\n",
    "                            '''请使用'glm-4', 'glm-4v', 'glm-3-turbo' 中的一个作为model的参数''')\n",
    "    elif model in llm_list[:3]:\n",
    "        llm = ZhipuAI()\n",
    "    qa_pairs = []\n",
    "\n",
    "    for text in tqdm(texts):\n",
    "        if len(text) > 200:\n",
    "            prompt = PROMPT.format(\n",
    "                context_str=text,\n",
    "                num_questions_per_page=num_questions_per_page\n",
    "            )\n",
    "            response = llm.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": prompt},\n",
    "                ],\n",
    "            )\n",
    "            matches = re.findall(\n",
    "                r'问题\\d+：(.*?)原文内容\\d+：(.*?)((?=问题\\d+：)|$)',\n",
    "                response.choices[0].message.content,\n",
    "                re.DOTALL\n",
    "            )\n",
    "            for _, match in enumerate(matches):\n",
    "                qa = {\n",
    "                    'query': match[0].strip(),\n",
    "                    'answer': match[1].strip()\n",
    "                }\n",
    "                qa_pairs.append(qa)\n",
    "    return QaPairs(qa_pairs=qa_pairs)\n",
    "\n",
    "def docs_generate_qa_pairs(\n",
    "        docs: List[Document], \n",
    "        num_questions_per_page: int = 1,\n",
    "        model: str = 'glm-4'\n",
    ") -> QaPairs:\n",
    "    '''借助大模型从给定的docs里提取出问题与对应的答案'''\n",
    "    list_doc = [doc.page_content for doc in docs]\n",
    "    return list_generate_qa_pairs(list_doc, num_questions_per_page, model=model)\n",
    "\n",
    "\n",
    "def docs_generate_pdf_qa_pairs(\n",
    "        pdf_pages: List[Document],\n",
    "        num_questions_per_page: int = 1     ,\n",
    "        model: str = 'glm-4-flash',\n",
    ") -> QaPairs:\n",
    "    '''\n",
    "    借助大模型从给定的texts里提取出问题、答案\n",
    "    返回结果为问题、答案、所属页码\n",
    "    '''\n",
    "\n",
    "    if model not in llm_list:\n",
    "        raise ValueError('你选择的模型暂时不被支持'\n",
    "                            '''请使用'glm-4', 'glm-4v', 'glm-3-turbo'中的一个作为model的参数''')\n",
    "    elif model in llm_list[:3]:\n",
    "        llm = ZhipuAI(\n",
    "            api_key=\"652a160546149ef4e3ec0ff881beebfe.D3UaKuk7FmiUn9WQ\"\n",
    "        )\n",
    "\n",
    "    qa_pairs = []\n",
    "\n",
    "    for page in tqdm(pdf_pages):\n",
    "        if len(page.page_content) > 200:\n",
    "            prompt = PROMPT.format(\n",
    "                context_str=page.page_content,\n",
    "                num_questions_per_page=num_questions_per_page\n",
    "            )\n",
    "            response = llm.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": prompt},\n",
    "                ],\n",
    "            )\n",
    "            matches = re.findall(\n",
    "                r'问题\\d+：(.*?)原文内容\\d+：(.*?)((?=问题\\d+：)|$)',\n",
    "                response.choices[0].message.content,\n",
    "                re.DOTALL\n",
    "            )\n",
    "            for _, match in enumerate(matches):\n",
    "                qa = {\n",
    "                    'query': match[0].strip(),\n",
    "                    'answer': match[1].strip(),\n",
    "                    'page_num': page.metadata['page']\n",
    "                }\n",
    "                qa_pairs.append(qa)\n",
    "    return QaPairs(qa_pairs=qa_pairs)\n",
    "\n",
    "\n",
    "\n",
    "loader = PyMuPDFLoader(file_path=\"./24徐涛《核心考案》高清无水印PDF【公众号：薄荷考研】.pdf\")\n",
    "\n",
    "pdf_pages = loader.load()[231:238]\n",
    "\n",
    "qa_from_pdf = docs_generate_pdf_qa_pairs(pdf_pages)\n",
    "print(qa_from_pdf.qa_pairs)\n",
    "qa_from_pdf.save_json(\"train_dataset.json\")\n",
    "\n",
    "qa_pairs = QaPairs.from_json('train_dataset.json')\n",
    "examples = []\n",
    "# 将单个qa对转为InputExample并存入列表\n",
    "# examples = [InputExample(texts=[qa_pair['query'], qa_pair['answer']]) for qa_pair in qa_pairs.qa_pairs]\n",
    "for i in range(len(qa_pairs)):\n",
    "    example = qa_pairs[i]\n",
    "    examples.append(InputExample(texts=[qa_pair['query'], qa_pair['answer']))\n",
    "                                       \n",
    "train_examples = examples[:3]\n",
    "dev_examples = examples[3:]                                        \n",
    "\n",
    "# 将数据集转换为DataLoader形式\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=32)\n",
    "model = SentenceTransformer(model_name_or_path=\"./AI-ModelScope/tao-8k\", device=\"cuda\", cache_folder='./', trust_remote_code=True)\n",
    "train_loss = losses.ContrastiveLoss(model=model)\n",
    "# 实例化评估器，将每次训练后的模型在验证集上测试性能\n",
    "evaluator = BinaryClassificationEvaluator.from_input_examples(dev_examples, name='med-dev')\n",
    "# 定义模型保存路径\n",
    "model_save_path='./trained_tao'\n",
    "# 微调模型\n",
    "model.fit([(train_dataloader, train_loss)],\n",
    "          evaluator=evaluator,\n",
    "          epochs=10,\n",
    "          output_path=model_save_path,\n",
    "          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a8a6ca6-f571-4660-8398-638acb54018e",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-10-15T00:33:56.297967Z",
     "iopub.status.busy": "2024-10-15T00:33:56.297628Z",
     "iopub.status.idle": "2024-10-15T00:34:07.850061Z",
     "shell.execute_reply": "2024-10-15T00:34:07.849548Z",
     "shell.execute_reply.started": "2024-10-15T00:33:56.297946Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading [added_tokens.json]: 100%|██████████| 82.0/82.0 [00:00<00:00, 156B/s]\n",
      "Downloading [config.json]: 100%|██████████| 871/871 [00:00<00:00, 1.27kB/s]\n",
      "Downloading [configuration.json]: 100%|██████████| 47.0/47.0 [00:00<00:00, 110B/s]\n",
      "Downloading [pytorch_model.bin]: 100%|██████████| 636M/636M [00:03<00:00, 212MB/s]  \n",
      "Downloading [README.md]: 100%|██████████| 24.8k/24.8k [00:00<00:00, 46.7kB/s]\n",
      "Downloading [special_tokens_map.json]: 100%|██████████| 125/125 [00:00<00:00, 288B/s]\n",
      "Downloading [tokenizer.json]: 100%|██████████| 429k/429k [00:00<00:00, 902kB/s]\n",
      "Downloading [tokenizer_config.json]: 100%|██████████| 1.08k/1.08k [00:00<00:00, 2.62kB/s]\n",
      "Downloading [vocab.txt]: 100%|██████████| 107k/107k [00:00<00:00, 241kB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./AI-ModelScope/tao-8k'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from modelscope import snapshot_download\n",
    "snapshot_download('AI-ModelScope/tao-8k', cache_dir='./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c577b9cc-fcc0-41b1-a99c-452d17d4d54e",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2024-10-07T12:31:57.314785Z",
     "iopub.status.busy": "2024-10-07T12:31:57.314440Z",
     "iopub.status.idle": "2024-10-07T12:34:58.586169Z",
     "shell.execute_reply": "2024-10-07T12:34:58.585628Z",
     "shell.execute_reply.started": "2024-10-07T12:31:57.314768Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "创建模型\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name AI-ModelScope/tao-8k. Creating a new one with mean pooling.\n",
      "Detected kernel version 4.19.91, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "创建评估器\n",
      "开始微调\n",
      "[2024-10-07 20:32:45,832] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
      "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3\n",
      "\u001b[93m [WARNING] \u001b[0m using untested triton version (2.3.1), only 1.0.0 is known to be compatible\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 02:09, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Dev Cosine Accuracy</th>\n",
       "      <th>Dev Cosine Accuracy Threshold</th>\n",
       "      <th>Dev Cosine F1</th>\n",
       "      <th>Dev Cosine F1 Threshold</th>\n",
       "      <th>Dev Cosine Precision</th>\n",
       "      <th>Dev Cosine Recall</th>\n",
       "      <th>Dev Cosine Ap</th>\n",
       "      <th>Dev Dot Accuracy</th>\n",
       "      <th>Dev Dot Accuracy Threshold</th>\n",
       "      <th>Dev Dot F1</th>\n",
       "      <th>Dev Dot F1 Threshold</th>\n",
       "      <th>Dev Dot Precision</th>\n",
       "      <th>Dev Dot Recall</th>\n",
       "      <th>Dev Dot Ap</th>\n",
       "      <th>Dev Manhattan Accuracy</th>\n",
       "      <th>Dev Manhattan Accuracy Threshold</th>\n",
       "      <th>Dev Manhattan F1</th>\n",
       "      <th>Dev Manhattan F1 Threshold</th>\n",
       "      <th>Dev Manhattan Precision</th>\n",
       "      <th>Dev Manhattan Recall</th>\n",
       "      <th>Dev Manhattan Ap</th>\n",
       "      <th>Dev Euclidean Accuracy</th>\n",
       "      <th>Dev Euclidean Accuracy Threshold</th>\n",
       "      <th>Dev Euclidean F1</th>\n",
       "      <th>Dev Euclidean F1 Threshold</th>\n",
       "      <th>Dev Euclidean Precision</th>\n",
       "      <th>Dev Euclidean Recall</th>\n",
       "      <th>Dev Euclidean Ap</th>\n",
       "      <th>Dev Max Accuracy</th>\n",
       "      <th>Dev Max Accuracy Threshold</th>\n",
       "      <th>Dev Max F1</th>\n",
       "      <th>Dev Max F1 Threshold</th>\n",
       "      <th>Dev Max Precision</th>\n",
       "      <th>Dev Max Recall</th>\n",
       "      <th>Dev Max Ap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.866557</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>658.337585</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>349.931885</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>14.190307</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>658.337585</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.866535</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>658.266541</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>349.945862</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>14.190795</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>658.266541</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.866497</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>658.144043</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>349.969482</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>14.191639</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>658.144043</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.866444</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>657.973450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>350.002380</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>14.192799</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>657.973450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.866375</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>657.753906</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>350.044434</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>14.194283</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>657.753906</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.866291</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>657.483643</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>350.096252</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>14.196138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>657.483643</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.866190</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>657.162964</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>350.155609</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>14.198342</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>657.162964</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.866072</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>656.791565</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>350.227783</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>14.200970</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>656.791565</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.865937</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>656.372070</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>350.309998</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>14.204041</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>656.372070</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.865788</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>655.906738</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>350.398865</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>14.207369</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>655.906738</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1030: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1030: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1030: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1030: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1030: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1030: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1030: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1030: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1030: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1030: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1030: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1030: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1030: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1030: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1030: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1030: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1030: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1030: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1030: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1030: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1030: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1030: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1030: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1030: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1030: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1030: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1030: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1030: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1030: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1030: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1030: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1030: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1030: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1030: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1030: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1030: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1030: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1030: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1030: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1030: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from sentence_transformers import InputExample, SentenceTransformer\n",
    "from sentence_transformers.evaluation import BinaryClassificationEvaluator\n",
    "from zhipuai import ZhipuAI\n",
    "from sentence_transformers import losses\n",
    "import re\n",
    "import json\n",
    "from langchain_core.documents import Document\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from zhipuai import ZhipuAI\n",
    "class QaPairs():\n",
    "    '''存储List[dict]类型数据'''\n",
    "\n",
    "    def __init__(self, qa_pairs: List[dict]):\n",
    "        self.qa_pairs = qa_pairs\n",
    "        \n",
    "\n",
    "    def save_json(self, path: str):\n",
    "        '''将数据存储为json格式'''\n",
    "\n",
    "        with open(path, \"w\", encoding='utf-8') as f:\n",
    "            json.dump(self.qa_pairs, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    @classmethod\n",
    "    def from_json(cls, path:str) -> 'QaPairs':\n",
    "        '''读取json格式数据'''\n",
    "\n",
    "        with open(path) as f:\n",
    "            data = json.load(f)\n",
    "        return cls(data)\n",
    "\n",
    "qa_pairs = QaPairs.from_json('./train_dataset.json')\n",
    "examples = []\n",
    "# 将单个qa对转为InputExample并存入列表\n",
    "examples = [InputExample(texts=[qa_pair['query'], qa_pair['answer']]) for qa_pair in qa_pairs.qa_pairs]\n",
    "train_examples = examples[:150]\n",
    "dev_examples = examples[150:]                                        \n",
    "\n",
    "# 将数据集转换为DataLoader形式\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=32)\n",
    "print(\"创建模型\")\n",
    "model = SentenceTransformer(model_name_or_path=\"AI-ModelScope/tao-8k\", device='cuda', cache_folder='./', trust_remote_code=True)\n",
    "model.max_seq_length = 256\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model=model)\n",
    "print(\"创建评估器\")\n",
    "# 实例化评估器，将每次训练后的模型在验证集上测试性能\n",
    "evaluator = BinaryClassificationEvaluator.from_input_examples(dev_examples, name='dev')\n",
    "# 定义模型保存路径\n",
    "model_save_path='./trained_tao'  \n",
    "# 微调模型\n",
    "print(\"开始微调\")\n",
    "model.fit([(train_dataloader, train_loss)],\n",
    "          evaluator=evaluator,\n",
    "          epochs=10,\n",
    "          output_path=model_save_path,\n",
    "          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522f0f8b-dc1e-415e-b0c5-efe84427e6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_pairs = QaPairs.from_json('train_dataset.json')\n",
    "examples = []\n",
    "# 将单个qa对转为InputExample并存入列表\n",
    "examples = [InputExample(texts=[qa_pair['query'], qa_pair['answer']]) for qa_pair in qa_pairs.qa_pairs]\n",
    "train_examples = examples[:150]\n",
    "dev_examples = examples[150:]                                        \n",
    "\n",
    "# 将数据集转换为DataLoader形式\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=32)\n",
    "print(\"创建model\")\n",
    "model = SentenceTransformer(model_name_or_path=\"AI-ModelScope/tao-8k\", device=\"cuda\", cache_folder='./', trust_remote_code=True)\n",
    "train_loss = losses.ContrastiveLoss(model=model)\n",
    "# 实例化评估器，将每次训练后的模型在验证集上测试性能\n",
    "print(\"创建评估器\")\n",
    "evaluator = BinaryClassificationEvaluator.from_input_examples(dev_examples, name='dev')\n",
    "# 定义模型保存路径\n",
    "model_save_path='./trained_tao'\n",
    "# 微调模型\n",
    "print(\"开始训练\")\n",
    "model.fit([(train_dataloader, train_loss)],\n",
    "          evaluator=evaluator,\n",
    "          epochs=10,\n",
    "          output_path=model_save_path,\n",
    "          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e7078ff-939a-4b18-a417-32eee511b35d",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-10-06T09:55:19.368791Z",
     "iopub.status.busy": "2024-10-06T09:55:19.368465Z",
     "iopub.status.idle": "2024-10-06T09:55:30.556269Z",
     "shell.execute_reply": "2024-10-06T09:55:30.555722Z",
     "shell.execute_reply.started": "2024-10-06T09:55:19.368773Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading [1_Pooling/config.json]: 100%|██████████| 190/190 [00:00<00:00, 323B/s]\n",
      "Downloading [config.json]: 100%|██████████| 776/776 [00:00<00:00, 1.75kB/s]\n",
      "Downloading [config_sentence_transformers.json]: 100%|██████████| 124/124 [00:00<00:00, 263B/s]\n",
      "Downloading [configuration.json]: 100%|██████████| 47.0/47.0 [00:00<00:00, 80.6B/s]\n",
      "Downloading [model.safetensors]: 100%|██████████| 91.4M/91.4M [00:01<00:00, 75.7MB/s]\n",
      "Downloading [modules.json]: 100%|██████████| 349/349 [00:00<00:00, 586B/s]\n",
      "Downloading [pytorch_model.bin]: 100%|██████████| 91.4M/91.4M [00:00<00:00, 128MB/s] \n",
      "Downloading [README.md]: 100%|██████████| 27.5k/27.5k [00:00<00:00, 54.9kB/s]\n",
      "Downloading [sentence_bert_config.json]: 100%|██████████| 52.0/52.0 [00:00<00:00, 73.1B/s]\n",
      "Downloading [special_tokens_map.json]: 100%|██████████| 125/125 [00:00<00:00, 216B/s]\n",
      "Downloading [tokenizer.json]: 100%|██████████| 429k/429k [00:00<00:00, 774kB/s]\n",
      "Downloading [tokenizer_config.json]: 100%|██████████| 367/367 [00:00<00:00, 714B/s]\n",
      "Downloading [vocab.txt]: 100%|██████████| 107k/107k [00:00<00:00, 190kB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./AI-ModelScope/bge-small-zh-v1___5'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from modelscope import snapshot_download\n",
    "snapshot_download('AI-ModelScope/bge-small-zh-v1.5', cache_dir='./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5974ece9-0ddb-411d-a5bd-0b955b765c74",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2024-10-14T15:41:11.716754Z",
     "iopub.status.busy": "2024-10-14T15:41:11.716411Z",
     "iopub.status.idle": "2024-10-14T15:41:11.942522Z",
     "shell.execute_reply": "2024-10-14T15:41:11.941818Z",
     "shell.execute_reply.started": "2024-10-14T15:41:11.716728Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Parameters to generic types must be types. Got {'anchor': '根据文本，党的十九大确立了哪一思想作为指导思想？', 'positive': '—（党的十九大的举行）\\n—（确立习近平新时代中国特色社会主义思想为指导思想）\\n坚持党的全面领.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mQaPairs\u001b[39;00m():\n\u001b[1;32m     24\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''存储List[dict]类型数据'''\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, qa_pairs: List[\u001b[38;5;28mdict\u001b[39m]):\n",
      "Cell \u001b[0;32mIn[9], line 26\u001b[0m, in \u001b[0;36mQaPairs\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mQaPairs\u001b[39;00m():\n\u001b[1;32m     24\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''存储List[dict]类型数据'''\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, qa_pairs: \u001b[43mList\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m]\u001b[49m):\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqa_pairs \u001b[38;5;241m=\u001b[39m qa_pairs\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_json\u001b[39m(\u001b[38;5;28mself\u001b[39m, path: \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/typing.py:312\u001b[0m, in \u001b[0;36m_tp_cache.<locals>.decorator.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# All real errors (not unhashable args) are raised below.\u001b[39;00m\n\u001b[0;32m--> 312\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/typing.py:1143\u001b[0m, in \u001b[0;36m_SpecialGenericAlias.__getitem__\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m   1141\u001b[0m     params \u001b[38;5;241m=\u001b[39m (params,)\n\u001b[1;32m   1142\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameters to generic types must be types.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1143\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_type_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1144\u001b[0m _check_generic(\u001b[38;5;28mself\u001b[39m, params, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nparams)\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy_with(params)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/typing.py:1143\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1141\u001b[0m     params \u001b[38;5;241m=\u001b[39m (params,)\n\u001b[1;32m   1142\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameters to generic types must be types.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1143\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[43m_type_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m params)\n\u001b[1;32m   1144\u001b[0m _check_generic(\u001b[38;5;28mself\u001b[39m, params, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nparams)\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy_with(params)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/typing.py:176\u001b[0m, in \u001b[0;36m_type_check\u001b[0;34m(arg, msg, is_argument, module, allow_special_forms)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arg\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(arg):\n\u001b[0;32m--> 176\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;132;01m!r:\u001b[39;00m\u001b[38;5;124m.100\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arg\n",
      "\u001b[0;31mTypeError\u001b[0m: Parameters to generic types must be types. Got {'anchor': '根据文本，党的十九大确立了哪一思想作为指导思想？', 'positive': '—（党的十九大的举行）\\n—（确立习近平新时代中国特色社会主义思想为指导思想）\\n坚持党的全面领."
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import Dataset\n",
    "from sentence_transformers import (\n",
    "    SentenceTransformer,\n",
    "    SentenceTransformerTrainer,\n",
    "    SentenceTransformerTrainingArguments,\n",
    "    SentenceTransformerModelCardData,\n",
    ")\n",
    "from sentence_transformers.losses import MultipleNegativesRankingLoss\n",
    "from sentence_transformers.training_args import BatchSamplers\n",
    "from sentence_transformers.evaluation import TripletEvaluator\n",
    "from typing import List\n",
    "import sentence_transformers\n",
    "from sentence_transformers import InputExample, SentenceTransformer\n",
    "from sentence_transformers.evaluation import BinaryClassificationEvaluator, MSEEvaluator,RerankingEvaluator\n",
    "# from zhipuai import ZhipuAI\n",
    "from sentence_transformers import losses\n",
    "import re\n",
    "import json\n",
    "from langchain_core.documents import Document\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "class QaPairs():\n",
    "    '''存储List[dict]类型数据'''\n",
    "\n",
    "    def __init__(self, qa_pairs: List[dict]):\n",
    "        self.qa_pairs = qa_pairs\n",
    "        \n",
    "\n",
    "    def save_json(self, path: str):\n",
    "        '''将数据存储为json格式'''\n",
    "\n",
    "        with open(path, \"w\", encoding='utf-8') as f:\n",
    "            json.dump(self.qa_pairs, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    @classmethod\n",
    "    def from_json(cls, path:str) -> 'QaPairs':\n",
    "        '''读取json格式数据'''\n",
    "\n",
    "        with open(path) as f:\n",
    "            data = json.load(f)\n",
    "        return cls(data)\n",
    "\n",
    "\n",
    "qa_pairs = QaPairs.from_json('train_dataset1.json')\n",
    "query=[]\n",
    "answer=[]\n",
    "i=0\n",
    "for qa_pair in qa_pairs.qa_pairs:\n",
    "            if i == 800:\n",
    "                break\n",
    "            i=i+1\n",
    "            query.append(qa_pair['query'])\n",
    "            answer.append(qa_pair['answer'])\n",
    "\n",
    "dataset = Dataset.from_dict({\n",
    "    \"query\": query,\n",
    "    \"answer\": answer\n",
    "})\n",
    "print(dataset)\n",
    "query=[]\n",
    "answer=[]\n",
    "i=800\n",
    "for qa_pair in qa_pairs.qa_pairs:\n",
    "            if i == 990:\n",
    "                break\n",
    "            i=i+1\n",
    "            query.append(qa_pair['query'])\n",
    "            answer.append(qa_pair['answer'])\n",
    "\n",
    "eval_dataset = Dataset.from_dict({\n",
    "    \"query\": query,\n",
    "    \"answer\": answer\n",
    "})\n",
    "label = [1]*190\n",
    "\n",
    "print(dataset)\n",
    "print(\"创建模型\")\n",
    "model = SentenceTransformer(model_name_or_path=\"AI-ModelScope/tao-8k\", device='cuda', cache_folder='./', trust_remote_code=True)\n",
    "model.max_seq_length = 200\n",
    "evaluator = BinaryClassificationEvaluator(query, answer, label, name='dev')\n",
    "evaluator(model)\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    # Required parameter:\n",
    "    output_dir=\"./\",\n",
    "    # Optional training parameters:\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=4,\n",
    "    learning_rate=2e-5,\n",
    "    warmup_ratio=0.1,\n",
    "    fp16=True,  # Set to False if you get an error that your GPU can't run on FP16\n",
    "    bf16=True,  # Set to True if you have a GPU that supports BF16\n",
    "    batch_sampler=BatchSamplers.NO_DUPLICATES,  # losses that use \"in-batch negatives\" benefit from no duplicates\n",
    "    # Optional tracking/debugging parameters:\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=10,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=10,\n",
    "    save_total_limit=2,\n",
    "    logging_steps=10,\n",
    "    run_name=\"mpnet-base-all-nli-triplet\",  # Will be used in W&B if `wandb` is installed\n",
    ")\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model=model)\n",
    "\n",
    "# 定义模型保存路径\n",
    "model_save_path='./trained_tao'\n",
    "# 微调模型\n",
    "print(\"开始微调\")\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=dataset,\n",
    "    loss=train_loss,\n",
    "    eval_dataset=eval_dataset,\n",
    "    evaluator=evaluator\n",
    ")\n",
    "trainer.train()\n",
    "print(\"训练结束！\")\n",
    "\n",
    " \n",
    "model.save_pretrained(model_save_path)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f862291-582e-42ef-9766-aeeea0d68fd2",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-10-15T01:00:43.981322Z",
     "iopub.status.busy": "2024-10-15T01:00:43.980898Z",
     "iopub.status.idle": "2024-10-15T01:04:05.778362Z",
     "shell.execute_reply": "2024-10-15T01:04:05.756215Z",
     "shell.execute_reply.started": "2024-10-15T01:00:43.981300Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['anchor', 'positive', 'negative'],\n",
      "    num_rows: 351\n",
      "})\n",
      "Dataset({\n",
      "    features: ['anchor', 'positive', 'negative'],\n",
      "    num_rows: 87\n",
      "})\n",
      "创建模型\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name AI-ModelScope/tao-8k. Creating a new one with mean pooling.\n",
      "Detected kernel version 4.19.91, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始微调\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='110' max='110' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [110/110 02:34, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Dev Cosine Accuracy</th>\n",
       "      <th>Dev Dot Accuracy</th>\n",
       "      <th>Dev Manhattan Accuracy</th>\n",
       "      <th>Dev Euclidean Accuracy</th>\n",
       "      <th>Dev Max Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.880600</td>\n",
       "      <td>0.191515</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.287200</td>\n",
       "      <td>0.126954</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.169800</td>\n",
       "      <td>0.146247</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.034400</td>\n",
       "      <td>0.147544</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.039700</td>\n",
       "      <td>0.139132</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.133784</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.012600</td>\n",
       "      <td>0.136157</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>0.140094</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.141698</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.141937</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.142097</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练结束！\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import Dataset\n",
    "from sentence_transformers import (\n",
    "    SentenceTransformer,\n",
    "    SentenceTransformerTrainer,\n",
    "    SentenceTransformerTrainingArguments,\n",
    "    SentenceTransformerModelCardData,\n",
    ")\n",
    "from sentence_transformers.losses import MultipleNegativesRankingLoss\n",
    "from sentence_transformers.training_args import BatchSamplers\n",
    "from sentence_transformers.evaluation import TripletEvaluator\n",
    "from typing import List\n",
    "import sentence_transformers\n",
    "from sentence_transformers import InputExample, SentenceTransformer\n",
    "from sentence_transformers.evaluation import BinaryClassificationEvaluator, MSEEvaluator,RerankingEvaluator\n",
    "# from zhipuai import ZhipuAI\n",
    "from sentence_transformers import losses\n",
    "import re\n",
    "import json\n",
    "from langchain_core.documents import Document\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "with open('data.json', 'r', encoding='utf-8') as f:\n",
    "    # 使用json.load函数加载JSON数据,dataset为dict类型\n",
    "    dataset = json.load(f)\n",
    "    \n",
    "train_anchor = []\n",
    "train_positive = []\n",
    "train_negative = []\n",
    "eval_anchor = []\n",
    "eval_positive = []\n",
    "eval_negative = []\n",
    "train_dataset = []\n",
    "for i in range(0, 351):\n",
    "    # dict = {}\n",
    "    # dict['anchor'] = dataset['anchor'][i]\n",
    "    # dict['positive'] = dataset['positive'][i]\n",
    "    # dict['negative'] = dataset['negative'][i]\n",
    "    # train_dataset.append(dict)\n",
    "    train_anchor.append(dataset['anchor'][i])\n",
    "    train_positive.append(dataset['positive'][i])\n",
    "    train_negative.append(dataset['negative'][i])\n",
    "train_dataset =  Dataset.from_dict({\n",
    "    \"anchor\": train_anchor,\n",
    "    \"positive\": train_positive,\n",
    "    \"negative\": train_negative\n",
    "})\n",
    "eval_dataset = []\n",
    "for i in range(351, 438):\n",
    "    # dict = {}\n",
    "    # dict['anchor'] = dataset['anchor'][i]\n",
    "    # dict['positive'] = dataset['positive'][i]\n",
    "    # dict['negative'] = dataset['negative'][i]\n",
    "    # eval_dataset.append(dict)\n",
    "    eval_anchor.append(dataset['anchor'][i])\n",
    "    eval_positive.append(dataset['positive'][i])\n",
    "    eval_negative.append(dataset['negative'][i])\n",
    "\n",
    "eval_dataset =  Dataset.from_dict({\n",
    "    \"anchor\": eval_anchor,\n",
    "    \"positive\": eval_positive,\n",
    "    \"negative\": eval_negative\n",
    "})\n",
    "print(train_dataset)\n",
    "print(eval_dataset)\n",
    "print(\"创建模型\")\n",
    "model = SentenceTransformer(model_name_or_path=\"AI-ModelScope/tao-8k\", device='cuda', cache_folder='./', trust_remote_code=True)\n",
    "model.max_seq_length = 200\n",
    "evaluator = TripletEvaluator(\n",
    "    anchors=eval_anchor,\n",
    "    positives=eval_positive,\n",
    "    negatives=eval_negative,\n",
    "    name=\"dev\"\n",
    ")\n",
    "\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    # Required parameter:\n",
    "    output_dir=\"./\",\n",
    "    # Optional training parameters:\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=2e-5,\n",
    "    warmup_ratio=0.1,\n",
    "    fp16=True,  # Set to False if you get an error that your GPU can't run on FP16\n",
    "    bf16=False,  # Set to True if you have a GPU that supports BF16\n",
    "    batch_sampler=BatchSamplers.NO_DUPLICATES,  # losses that use \"in-batch negatives\" benefit from no duplicates\n",
    "    # Optional tracking/debugging parameters:\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=10,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=10,\n",
    "    save_total_limit=2,\n",
    "    logging_steps=10,\n",
    "    run_name=\"mpnet-base-all-nli-triplet\",  # Will be used in W&B if `wandb` is installed\n",
    ")\n",
    "\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model=model)\n",
    "\n",
    "# 定义模型保存路径\n",
    "model_save_path='./trained_tao1'\n",
    "# 微调模型\n",
    "print(\"开始微调\")\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    loss=train_loss,\n",
    "    eval_dataset=eval_dataset,\n",
    "    evaluator=evaluator\n",
    ")\n",
    "trainer.train()\n",
    "print(\"训练结束！\")\n",
    "\n",
    "model.save_pretrained(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b76e290-f435-4cdf-a726-6bcb5fe2248d",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-10-14T15:50:56.113530Z",
     "iopub.status.busy": "2024-10-14T15:50:56.113234Z",
     "iopub.status.idle": "2024-10-14T15:51:00.768936Z",
     "shell.execute_reply": "2024-10-14T15:51:00.768427Z",
     "shell.execute_reply.started": "2024-10-14T15:50:56.113510Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'query': '1111', 'answer': 'aaaaaa', 'page_num': 15}, {'query': '222', 'answer': 'bbbbbb。', 'page_num': 15}]\n",
      "Dataset({\n",
      "    features: ['query', 'answer'],\n",
      "    num_rows: 4\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import Dataset\n",
    "from sentence_transformers import (\n",
    "    SentenceTransformer,\n",
    "    SentenceTransformerTrainer,\n",
    "    SentenceTransformerTrainingArguments,\n",
    "    SentenceTransformerModelCardData,\n",
    ")\n",
    "from sentence_transformers.losses import MultipleNegativesRankingLoss\n",
    "from sentence_transformers.training_args import BatchSamplers\n",
    "from sentence_transformers.evaluation import TripletEvaluator\n",
    "from typing import List\n",
    "import sentence_transformers\n",
    "from sentence_transformers import InputExample, SentenceTransformer\n",
    "from sentence_transformers.evaluation import BinaryClassificationEvaluator, MSEEvaluator,RerankingEvaluator\n",
    "# from zhipuai import ZhipuAI\n",
    "from sentence_transformers import losses\n",
    "import re\n",
    "import json\n",
    "from langchain_core.documents import Document\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "class QaPairs():\n",
    "    '''存储List[dict]类型数据'''\n",
    "\n",
    "    def __init__(self, qa_pairs: List[dict]):\n",
    "        self.qa_pairs = qa_pairs\n",
    "        \n",
    "\n",
    "    def save_json(self, path: str):\n",
    "        '''将数据存储为json格式'''\n",
    "\n",
    "        with open(path, \"w\", encoding='utf-8') as f:\n",
    "            json.dump(self.qa_pairs, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    @classmethod\n",
    "    def from_json(cls, path:str) -> 'QaPairs':\n",
    "        '''读取json格式数据'''\n",
    "\n",
    "        with open(path) as f:\n",
    "            data = json.load(f)\n",
    "        return cls(data)\n",
    "\n",
    "qa_pairs = QaPairs.from_json('ttt.json')\n",
    "print(qa_pairs.qa_pairs)\n",
    "query=[1,2,3,4]\n",
    "answer=['a','b','c','d']\n",
    "dataset = Dataset.from_dict({\n",
    "    \"query\": query,\n",
    "    \"answer\": answer\n",
    "})\n",
    "print(dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
